{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COE_197z_MLP_on_CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SNFZ7TiSiTSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14314
        },
        "outputId": "6b2c78b1-b9af-4135-a586-45ed27b30e30"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import cv2\n",
        "\n",
        "#MLP ON CIFAR\n",
        "\n",
        "# network parameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 25\n",
        "data_augmentation = True\n",
        "\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "image_size = x_train.shape[1]\n",
        "# print('xtrain shape: ', x_train[0].shape)\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.imshow(x_train[0])\n",
        "# plt.show()\n",
        "# cv2.imshow(\"train\", x_train[0])\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "x_train = x_train.reshape(-1, 3072)\n",
        "x_test = x_test.reshape(-1, 3072)\n",
        "x_train = x_train.astype('float32') / 255;\n",
        "x_test = x_test.astype('float32') / 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "input_size = 3072\n",
        "max_batches = len(x_train) / batch_size\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# model is a 3-layer MLP with ReLU and dropout after each layer\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=input_size))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.40))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.08))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.12))\n",
        "model.add(Dense(num_classes))\n",
        "# this is the output for one-hot vector\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "plot_model(model, to_file='mlp-cifar.png', show_shapes=True)\n",
        "\n",
        "# loss function for one-hot vector\n",
        "# use of sgd optimizer with default lr=0.01\n",
        "# accuracy is good metric for classification tasks\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    # train the network no data augmentation\n",
        "    x_train = np.reshape(x_train, [-1, input_size])\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    # we need [width, height, channel] dim for data aug\n",
        "    x_train = np.reshape(x_train, [-1, image_size, image_size, 3])\n",
        "    datagen = ImageDataGenerator(\n",
        "        data_format=\"channels_last\",\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0.0,  # randomly rotate images in the range (deg 0 to 180)\n",
        "        width_shift_range=0.0,  # randomly shift images horizontally\n",
        "        height_shift_range=0.0,  # randomly shift images vertically\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    datagen.fit(x_train)\n",
        "    for e in range(epochs):\n",
        "        print(\"Epoch: %d/%d\" % (e+1, epochs))\n",
        "        batches = 0\n",
        "        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):\n",
        "            x_batch = np.reshape(x_batch, [-1, input_size])\n",
        "            if e == 24:\n",
        "                model.fit(x_batch, y_batch, verbose=1)\n",
        "            else:\n",
        "                model.fit(x_batch, y_batch, verbose=0)\n",
        "            batches += 1\n",
        "            if batches >= max_batches:\n",
        "                # we need to break the loop by hand because\n",
        "                # the generator loops indefinitely\n",
        "                break\n",
        "\n",
        "# Score trained model.\n",
        "x_test = np.reshape(x_test, [-1, input_size])\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 3072)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_141 (Dense)            (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "activation_141 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_142 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_79 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_143 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_80 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_144 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,103,818\n",
            "Trainable params: 2,103,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Using real-time data augmentation.\n",
            "Epoch: 1/25\n",
            "Epoch: 2/25\n",
            "Epoch: 3/25\n",
            "Epoch: 4/25\n",
            "Epoch: 5/25\n",
            "Epoch: 6/25\n",
            "Epoch: 7/25\n",
            "Epoch: 8/25\n",
            "Epoch: 9/25\n",
            "Epoch: 10/25\n",
            "Epoch: 11/25\n",
            "Epoch: 12/25\n",
            "Epoch: 13/25\n",
            "Epoch: 14/25\n",
            "Epoch: 15/25\n",
            "Epoch: 16/25\n",
            "Epoch: 17/25\n",
            "Epoch: 18/25\n",
            "Epoch: 19/25\n",
            "Epoch: 20/25\n",
            "Epoch: 21/25\n",
            "Epoch: 22/25\n",
            "Epoch: 23/25\n",
            "Epoch: 24/25\n",
            "Epoch: 25/25\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.2613 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.2579 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3445 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.3181 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.3379 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.3707 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 285us/step - loss: 1.2437 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2135 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 308us/step - loss: 1.2478 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 290us/step - loss: 1.3066 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 275us/step - loss: 1.3022 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3004 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 280us/step - loss: 1.1720 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 274us/step - loss: 1.2127 - acc: 0.6094\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 281us/step - loss: 1.5361 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 292us/step - loss: 1.2370 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 331us/step - loss: 1.3158 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.4031 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 320us/step - loss: 1.5370 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.4127 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 324us/step - loss: 1.3385 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.3920 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.0698 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.2691 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 315us/step - loss: 1.0477 - acc: 0.6094\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2362 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.2507 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2337 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.2955 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3496 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 308us/step - loss: 1.1484 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 286us/step - loss: 1.4174 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.1370 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.4029 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.2376 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.1090 - acc: 0.6172\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.3318 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 355us/step - loss: 1.2120 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 316us/step - loss: 1.4301 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 324us/step - loss: 1.1259 - acc: 0.6250\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.2748 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.3011 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.3425 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 328us/step - loss: 1.2855 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.4072 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.2182 - acc: 0.6172\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.2389 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 327us/step - loss: 1.1967 - acc: 0.5938\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.2691 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 331us/step - loss: 1.2285 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.3153 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.4695 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.2481 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 322us/step - loss: 1.4217 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.2571 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 288us/step - loss: 1.3029 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 292us/step - loss: 1.2870 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 318us/step - loss: 1.1481 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.1259 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 362us/step - loss: 1.3015 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 309us/step - loss: 1.3091 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.4370 - acc: 0.4453\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 337us/step - loss: 1.2999 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.4733 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2495 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.1527 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.3531 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 327us/step - loss: 1.3553 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 325us/step - loss: 1.1036 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.2050 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.4769 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 315us/step - loss: 1.2641 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 316us/step - loss: 1.3784 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.3091 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3620 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 320us/step - loss: 1.3028 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.4430 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.3201 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 326us/step - loss: 1.3671 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 331us/step - loss: 1.1230 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.3317 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 380us/step - loss: 1.3609 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.2120 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3821 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 318us/step - loss: 1.4687 - acc: 0.4375\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.3735 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 323us/step - loss: 1.3096 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.1573 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3430 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 318us/step - loss: 1.2958 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.3037 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.3352 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.2914 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2797 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 343us/step - loss: 1.2366 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.2404 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.2038 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 324us/step - loss: 1.2952 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 320us/step - loss: 1.4238 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.1312 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 309us/step - loss: 1.2392 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 325us/step - loss: 1.3459 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 402us/step - loss: 1.1954 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3682 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.1716 - acc: 0.6250\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.2189 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.3527 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 337us/step - loss: 1.1570 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 328us/step - loss: 1.3374 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.3049 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.2941 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 329us/step - loss: 1.3305 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.1194 - acc: 0.6172\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.3259 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.3170 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 324us/step - loss: 1.4671 - acc: 0.4375\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 318us/step - loss: 1.3580 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 326us/step - loss: 1.2631 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.2413 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 286us/step - loss: 1.4077 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.1688 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.2610 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.1836 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 397us/step - loss: 1.3838 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 329us/step - loss: 1.3351 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.2955 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 308us/step - loss: 1.2670 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.2741 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 320us/step - loss: 1.4625 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.2558 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.2625 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.1801 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.3238 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.1953 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 316us/step - loss: 1.4005 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 333us/step - loss: 1.3217 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.2907 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.1131 - acc: 0.6797\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 295us/step - loss: 1.3713 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 328us/step - loss: 1.3075 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.2310 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.1202 - acc: 0.6094\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.3980 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 337us/step - loss: 1.3879 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.3653 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 402us/step - loss: 1.3027 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 316us/step - loss: 1.1979 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 282us/step - loss: 1.2863 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.2910 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.3250 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.3579 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 318us/step - loss: 1.3702 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 352us/step - loss: 1.3260 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.2843 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 282us/step - loss: 1.4078 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.3489 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.3280 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.3109 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.3366 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 323us/step - loss: 1.3522 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.2480 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.1880 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.2690 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 295us/step - loss: 1.2971 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.3578 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 332us/step - loss: 1.3667 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.2983 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 328us/step - loss: 1.2447 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.5188 - acc: 0.4141\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 290us/step - loss: 1.3379 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 292us/step - loss: 1.1650 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.2134 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 286us/step - loss: 1.2577 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.3394 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.2650 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.2107 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.2196 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.1980 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.1701 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.1235 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 315us/step - loss: 1.2315 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.1657 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.2054 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.3253 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 326us/step - loss: 1.1428 - acc: 0.6484\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.4352 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.2829 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.1826 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 339us/step - loss: 1.2954 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 331us/step - loss: 1.2808 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.4348 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.4690 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 315us/step - loss: 1.4703 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.4053 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.2779 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.1307 - acc: 0.5938\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.5124 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.2736 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.0875 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.2867 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.4270 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.2576 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.2936 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.3362 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2557 - acc: 0.6172\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2181 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.2092 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.2445 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.4136 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.4229 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 361us/step - loss: 1.1752 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 329us/step - loss: 1.1551 - acc: 0.6406\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.2088 - acc: 0.5938\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.4294 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 280us/step - loss: 1.3549 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.5019 - acc: 0.4375\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.4352 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.0392 - acc: 0.6172\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 285us/step - loss: 1.3346 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.4544 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 286us/step - loss: 1.2271 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 284us/step - loss: 1.4254 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.1766 - acc: 0.6094\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.1121 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.3632 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.3344 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.2636 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.2117 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.3846 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 308us/step - loss: 1.4847 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.3268 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.3399 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.4568 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 345us/step - loss: 1.3588 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.3519 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.1268 - acc: 0.6172\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 325us/step - loss: 1.2307 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 290us/step - loss: 1.4859 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 282us/step - loss: 1.3352 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.3779 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3783 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 285us/step - loss: 1.2149 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.2428 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.3377 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 280us/step - loss: 1.3038 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 287us/step - loss: 1.1994 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 284us/step - loss: 1.2470 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.3676 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 285us/step - loss: 1.3176 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.3999 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.2347 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 290us/step - loss: 1.2740 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.3289 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.4114 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.3449 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 369us/step - loss: 1.4021 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.3587 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.2757 - acc: 0.6094\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 326us/step - loss: 1.2261 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 322us/step - loss: 1.1918 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.0898 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.1724 - acc: 0.5938\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.4508 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 288us/step - loss: 1.2469 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.3103 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3985 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.4585 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 333us/step - loss: 1.3251 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.2734 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 284us/step - loss: 1.4145 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.6281 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3243 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.5226 - acc: 0.4062\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.2783 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.2566 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3072 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.2072 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 355us/step - loss: 1.3551 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3394 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 315us/step - loss: 1.3356 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 295us/step - loss: 1.3390 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 326us/step - loss: 1.4039 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3596 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.4837 - acc: 0.4062\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.3854 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 328us/step - loss: 1.3901 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.4617 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.4115 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 295us/step - loss: 1.2233 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 288us/step - loss: 1.2067 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 322us/step - loss: 1.2367 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 292us/step - loss: 1.2177 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.1909 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.1279 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 315us/step - loss: 1.4760 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.3031 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.3529 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 337us/step - loss: 1.2742 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.2205 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 387us/step - loss: 1.4164 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 289us/step - loss: 1.3676 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.2235 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 327us/step - loss: 1.3425 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 333us/step - loss: 1.2521 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.4224 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 328us/step - loss: 1.3770 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.3862 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 335us/step - loss: 1.3595 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 329us/step - loss: 1.2899 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.3358 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.2478 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.2587 - acc: 0.5781\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 299us/step - loss: 1.3399 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.4431 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.2851 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.3581 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.1590 - acc: 0.6016\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 309us/step - loss: 1.3443 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 291us/step - loss: 1.4586 - acc: 0.4062\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.4160 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 353us/step - loss: 1.3339 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.2127 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 322us/step - loss: 1.0254 - acc: 0.6719\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.1577 - acc: 0.6172\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.1945 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.2624 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.3872 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 327us/step - loss: 1.3302 - acc: 0.4766\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.2026 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 308us/step - loss: 1.2606 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.3212 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.1582 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.1028 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 320us/step - loss: 1.3704 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.2023 - acc: 0.5625\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 313us/step - loss: 1.3126 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 309us/step - loss: 1.5766 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.4994 - acc: 0.4375\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 318us/step - loss: 1.3392 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.2433 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 286us/step - loss: 1.4023 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 302us/step - loss: 1.4564 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 411us/step - loss: 1.2215 - acc: 0.5938\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3297 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.2397 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.2856 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 295us/step - loss: 1.2182 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 322us/step - loss: 1.3067 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.4627 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 296us/step - loss: 1.3921 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.4214 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.2377 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 306us/step - loss: 1.2414 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 318us/step - loss: 1.2534 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 327us/step - loss: 1.5259 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.0965 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.5178 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 319us/step - loss: 1.4682 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 314us/step - loss: 1.3593 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 363us/step - loss: 1.3121 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 292us/step - loss: 1.4511 - acc: 0.4453\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 317us/step - loss: 1.4137 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 308us/step - loss: 1.2442 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 327us/step - loss: 1.4041 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 338us/step - loss: 1.3483 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.4897 - acc: 0.4844\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 309us/step - loss: 1.1799 - acc: 0.5859\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 311us/step - loss: 1.3617 - acc: 0.4688\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 298us/step - loss: 1.3565 - acc: 0.5703\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 333us/step - loss: 1.3890 - acc: 0.4531\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.4347 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 312us/step - loss: 1.2525 - acc: 0.5391\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 321us/step - loss: 1.1529 - acc: 0.5469\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 293us/step - loss: 1.3883 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 308us/step - loss: 1.5248 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 303us/step - loss: 1.3391 - acc: 0.5312\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 309us/step - loss: 1.3938 - acc: 0.4922\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 289us/step - loss: 1.4569 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.3602 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 305us/step - loss: 1.2542 - acc: 0.5547\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 307us/step - loss: 1.3373 - acc: 0.5234\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 310us/step - loss: 1.2930 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 301us/step - loss: 1.3392 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 350us/step - loss: 1.3551 - acc: 0.5000\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 297us/step - loss: 1.2782 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 357us/step - loss: 1.3042 - acc: 0.5156\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 351us/step - loss: 1.4688 - acc: 0.4453\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 304us/step - loss: 1.3888 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 300us/step - loss: 1.3651 - acc: 0.5078\n",
            "Epoch 1/1\n",
            "128/128 [==============================] - 0s 294us/step - loss: 1.4552 - acc: 0.4609\n",
            "Epoch 1/1\n",
            "80/80 [==============================] - 0s 446us/step - loss: 1.2588 - acc: 0.5375\n",
            "10000/10000 [==============================] - 2s 228us/step\n",
            "Test loss: 1.449577223777771\n",
            "Test accuracy: 0.4927\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}